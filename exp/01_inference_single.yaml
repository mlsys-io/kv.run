apiVersion: mloc/v1
kind: InferenceTask
metadata:
  name: llama31-8b-single
  owner: demo
  annotations:
    description: "Single-turn vLLM inference over GSM8K (200 samples)"

spec:
  taskType: "inference"

  resources:
    replicas: 1
    hardware:
      cpu: "16"
      memory: "64Gi"
      gpu:
        type: "any"
        count: 2

  parallel:
    enabled: true
    max_shards: 2

  model:
    source:
      type: "huggingface"
      identifier: "meta-llama/Meta-Llama-3.1-8B-Instruct"
      revision: "main"
    vllm:
      tensor_parallel_size: 2
      gpu_memory_utilization: 0.9
      trust_remote_code: true

  data:
    type: "dataset"
    url: "openai/gsm8k"
    name: "main"
    split: "train[:200]"
    column: "question"
    shuffle: true
    seed: 42

  inference:
    system_prompt: |
      You are a precise math tutor. Provide concise, step-by-step answers to the question.
    max_tokens: 256
    temperature: 0.2
    top_p: 0.9

  output:
    destination:
      type: "local"
      path: "./runs/01_inference_single"
    artifacts:
      - "responses.json"
      - "logs"
