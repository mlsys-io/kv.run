# 先运行推理生成示范答案，再使用生成的对话进行轻量级 SFT 训练。
apiVersion: mloc/v1
kind: TrainingTask
metadata:
  name: llama1b-infer-then-sft
  owner: demo
  annotations:
    description: "Bootstrap GSM8K demonstrations via inference before fine-tuning with SFT"

spec:
  taskType: "sft"

  resources:
    replicas: 1
    hardware:
      cpu: "12"
      memory: "46Gi"
      gpu:
        type: "any"
        count: 1
        memory: "46Gi"

  model:
    source:
      type: "huggingface"
      identifier: "meta-llama/Llama-3.2-1B-Instruct"
      revision: "main"

  output:
    destination:
      type: "http"
      url: "http://localhost:8000/api/v1/results"
      timeoutSec: 1200
    artifacts:
      - "responses.json"
      - "final_model"

  stages:
    - name: gsm8k-bootstrap
      spec:
        taskType: "inference"
        model:
          source:
            type: "huggingface"
            identifier: "meta-llama/Llama-3.2-1B-Instruct"
            revision: "main"
          vllm:
            gpu_memory_utilization: 0.85
            trust_remote_code: true
        data:
          type: "dataset"
          url: "openai/gsm8k"
          name: "main"
          split: "train[:200]"
          column: "question"
          shuffle: true
          seed: 41
          metadata_columns:
            answer: "reference_answer"
        inference:
          system_prompt: |
            You are a careful math tutor. Solve the word problem step by step and end with "Final answer: <number>".
          max_tokens: 256
          temperature: 0.2
          top_p: 0.9
        postprocess:
          jsonl_export:
            path: "artifacts/sft_pairs.jsonl"
            fields:
              prompt:
                from: "metadata"
                key: "prompt"
              response:
                from: "output"
              reference_answer:
                from: "metadata"
                key: "reference_answer"
            required_fields:
              - "prompt"
              - "response"
        output:
          destination:
            type: "http"
            url: "http://localhost:8000/api/v1/results"
            timeoutSec: 30
          artifacts:
            - "artifacts/sft_pairs.jsonl"
            - "responses.json"
            - "logs"

    - name: sft-train
      spec:
        taskType: "sft"
        data:
          jsonl:
            path: "${gsm8k-bootstrap.result.jsonl_export.path}"
            url: "${gsm8k-bootstrap.result.jsonl_export.url}"
            prompt_field: "prompt"
            response_field: "response"
          separator: "\n\nAnswer: "
          max_samples: 200
        training:
          num_train_epochs: 1
          batch_size: 1
          gradient_accumulation_steps: 4
          learning_rate: 5.0e-5
          max_seq_length: 256
          logging_steps: 10
          save_steps: 500
          save_model: true
          gradient_checkpointing: true
          packing: false
          auto_deepspeed_stage: 2
        output:
          destination:
            type: "http"
            url: "http://localhost:8000/api/v1/results"
            timeoutSec: 1200
          artifacts:
            - "responses.json"
            - "final_model"
            - "logs"
