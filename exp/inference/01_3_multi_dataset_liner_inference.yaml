# 顺序在 GSM8K、TruthfulQA 与 MMLU 上运行 llama 1B 推理，比较跨领域表现并产出分阶段结果。
apiVersion: mloc/v1
kind: InferenceTask
metadata:
  name: llama1b-linear-multi-eval
  owner: demo
  annotations:
    description: "Sequential inference over math, factual QA, and MMLU-style multiple-choice datasets"

spec:
  taskType: "inference"

  resources:
    replicas: 1
    hardware:
      cpu: "12"
      memory: "48Gi"
      gpu:
        type: "any"
        count: 1
        memory: "24Gi"

  stages:
    - name: gsm8k-pass
      spec:
        taskType: "inference"
        model:
          source:
            type: "huggingface"
            identifier: "meta-llama/Llama-3.2-1B-Instruct"
            revision: "main"
          vllm:
            gpu_memory_utilization: 0.85
            trust_remote_code: true
        data:
          type: "dataset"
          url: "openai/gsm8k"
          name: "main"
          split: "train[:200]"
          column: "question"
          shuffle: true
          seed: 41
        inference:
          system_prompt: |
            You are a careful math tutor. Solve the word problem step by step and end with "Final answer: <number>".
          max_tokens: 256
          temperature: 0.2
          top_p: 0.9
        output:
          destination:
            type: "http"
            url: "http://localhost:8000/api/v1/results"
            timeoutSec: 30
          artifacts:
            - "responses.json"
            - "logs"

    - name: truthfulqa-pass
      spec:
        taskType: "inference"
        model:
          source:
            type: "huggingface"
            identifier: "meta-llama/Llama-3.2-3B-Instruct"
            revision: "main"
          vllm:
            gpu_memory_utilization: 0.85
            trust_remote_code: true
        data:
          type: "dataset"
          url: "truthfulqa/truthful_qa"
          name: "generation"
          split: "validation[:150]"
          column: "question"
          shuffle: true
          seed: 17
        inference:
          system_prompt: |
            You are an honesty-focused assistant. Provide concise and factual answers that avoid hallucinations.
          max_tokens: 192
          temperature: 0.15
          top_p: 0.85
        output:
          destination:
            type: "http"
            url: "http://localhost:8000/api/v1/results"
            timeoutSec: 30
          artifacts:
            - "responses.json"
            - "logs"

    - name: mmlu-pass
      spec:
        taskType: "inference"
        model:
          source:
            type: "huggingface"
            identifier: "meta-llama/Llama-3.2-3B-Instruct"
            revision: "main"
          vllm:
            gpu_memory_utilization: 0.85
            trust_remote_code: true
        data:
          type: "dataset"
          url: "cais/mmlu"
          name: "all"
          split: "test[:150]"
          column: "question"
          shuffle: true
          seed: 23
        inference:
          system_prompt: |
            You are answering an MMLU multiple-choice question. Consider the standard options (A/B/C/D), reason briefly, and return the final letter choice.
          max_tokens: 160
          temperature: 0.1
          top_p: 0.8
        output:
          destination:
            type: "http"
            url: "http://localhost:8000/api/v1/results"
            timeoutSec: 30
          artifacts:
            - "responses.json"
            - "logs"
