# lora_sft_mistral.yaml
#
# Example LoRA fine-tuning task using TRL SFTTrainer with PEFT configuration.
# Update model identifier and dataset settings for your workload.

apiVersion: mloc/v1
kind: LoRATask
metadata:
  name: gpt2-lora-demo

spec:
  taskType: "lora_sft"

  resources:
    replicas: 1
    hardware:
      cpu: "8"
      memory: "32GiB"
      gpu:
        count: 1
        type: "any"

  model:
    source:
      type: "huggingface"
      identifier: "mistralai/Mistral-7B-Instruct-v0.3"

  data:
    dataset_name: "lvwerra/stack-exchange-paired"
    split: "train[:1%]"
    prompt_column: "question"
    response_column: "chosen"
    separator: "\n\nAssistant: "
    max_samples: 200

  lora:
    r: 16
    alpha: 32
    dropout: 0.05
    target_modules:
      - "c_attn"
      - "c_proj"

  training:
    num_train_epochs: 1
    batch_size: 2
    gradient_accumulation_steps: 4
    learning_rate: 2.0e-4
    max_seq_length: 512
    logging_steps: 5
    save_steps: 50
    save_model: true

  output:
    destination:
      type: "local"
      path: "/mnt/mloc-results"
    artifacts:
      - "responses.json"
      - "final_lora"
