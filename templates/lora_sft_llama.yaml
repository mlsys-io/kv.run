# lora_sft_llama.yaml
#
# Example LoRA fine-tuning task using the generalized LoRASFTExecutor.
# Customize the model identifier, LoRA parameters, and dataset settings as needed.

apiVersion: mloc/v1
kind: LoRASFTTask
metadata:
  name: llama-lora-demo
  owner: research
  annotations:
    description: "LoRA fine-tuning pipeline for Llama models"

spec:
  taskType: "lora_sft"
  sloSeconds: 10

  resources:
    replicas: 1
    hardware:
      cpu: "8"
      memory: "48Gi"
      gpu:
        count: 1
        type: "any"

  model:
    source:
      type: "huggingface"
      identifier: "meta-llama/Llama-3.1-8B-Instruct"

  lora:
    r: 16
    alpha: 32
    dropout: 0.05
    bias: "none"
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
    task_type: "CAUSAL_LM"
    use_rslora: false

  data:
    dataset_name: "openai/gsm8k"
    config_name: "main"
    split: "train[:2%]"
    prompt_column: "question"
    response_column: "answer"
    separator: "\n\nAnswer: "
    max_samples: 200

  training:
    num_train_epochs: 1
    batch_size: 2
    gradient_accumulation_steps: 4
    learning_rate: 2.0e-4
    max_seq_length: 512
    logging_steps: 10
    save_steps: 100
    save_model: true
    gradient_checkpointing: false
    packing: false
    fp16: true
    bf16: false

  output:
    destination:
      type: "local"
      path: "./lora_sft_llama"
    artifacts:
      - "responses.json"
      - "logs"
      - "artifacts/lora_adapter"
